sqoop job \
--create retail_incremental_load \
-- import \
--connect jdbc:mysql://<database_host>/<database_name> \
--username <username> \
--password <password> \
--table <table_name> \
--hive-import \
--hive-overwrite \
--hive-table <hive_table_name> \
--create-hive-table \
--hive-drop-import-delims \
--incremental lastmodified \
--check-column <lastmodified_column_name> \
--merge-key <merge_key_column_name> \
--split-by <split_column_name> \
--as-ORCFile \
--delete-target-dir \
--num-mappers 5 \
--compress \
--compression-codec org.apache.hadoop.io.compress.SnappyCodec \
--direct \
--outdir <output_directory> \
--bindir <output_directory> \
--exclude-tables item,product


In this command, replace the following placeholders:

<database_host> with the hostname or IP address of the MySQL database server.
<database_name> with the name of the "retail" database.
<username> with the username to connect to the database.
<password> with the password to connect to the database.
<table_name> with the name of the table to import.
<hive_table_name> with the name of the Hive table to create or update.
<lastmodified_column_name> with the name of the column that contains the last modified time.
<merge_key_column_name> with the name of the column used to merge new data with old data.
<split_column_name> with the name of the column that should be used to split data into multiple mappers.

